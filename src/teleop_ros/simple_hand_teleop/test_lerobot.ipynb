{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset\n",
    "\n",
    "REPO_ID = \"yilin404/pick_and_place\"\n",
    "DATA_ROOT = \"/home/yilin/dataset/own_episode_data\"\n",
    "\n",
    "# Set up the dataset.\n",
    "delta_timestamps = {\n",
    "    # Load the previous image and state at -0.1 seconds before current frame,\n",
    "    # then load current image and state corresponding to 0.0 second.\n",
    "    \"observation.images.colors_camera_top\": [-0.1, 0.0],\n",
    "    \"observation.images.colors_camera_wrist\": [-0.1, 0.0],\n",
    "    \"observation.state\": [-0.1, 0.0],\n",
    "    # Load the previous action (-0.1), the next action to be executed (0.0),\n",
    "    # and 14 future actions with a 0.1 seconds spacing. All these actions will be\n",
    "    # used to supervise the policy.\n",
    "    \"action\": [-0.1, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4],\n",
    "}\n",
    "dataset = LeRobotDataset(REPO_ID, root=DATA_ROOT, delta_timestamps=delta_timestamps)\n",
    "\n",
    "# Create dataloader for offline training.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=0,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    pin_memory=device != torch.device(\"cpu\"),\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.common.policies.rdt.configuration_rdt import RDTConfig\n",
    "from lerobot.common.policies.rdt.modeling_rdt import RDTPolicy\n",
    "\n",
    "import torch\n",
    "\n",
    "# Set up the policy.\n",
    "config = RDTConfig()\n",
    "config.input_shapes = {\n",
    "    \"observation.images.colors_camera_top\": [3, 480, 640],\n",
    "    \"observation.images.colors_camera_wrist\": [3, 480, 640],\n",
    "    \"observation.state\": [7],\n",
    "}\n",
    "config.output_shapes = {\n",
    "    \"action\": [7],\n",
    "}\n",
    "config.input_normalization_modes = {\n",
    "    \"observation.images.colors_camera_top\": \"mean_std\",\n",
    "    \"observation.images.colors_camera_wrist\": \"mean_std\",\n",
    "    \"observation.state\": \"min_max\",\n",
    "}\n",
    "config.output_normalization_modes = {\n",
    "    \"action\": \"min_max\",\n",
    "}\n",
    "config.crop_shape = None\n",
    "policy = RDTPolicy(config, dataset_stats=dataset.stats)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "policy.to(device)\n",
    "for batch in dataloader:\n",
    "    # Move the batch to the device.\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "    # Forward pass.\n",
    "    loss = policy(batch)[\"loss\"]\n",
    "    print(\"==> loss is: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import json\n",
    "# import re\n",
    "# import tqdm\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# from typing import List\n",
    "\n",
    "# RAW_DIR = Path(\"/home/yilin/dataset/own_episode_data/raw_data/pick_and_place\")\n",
    "# JSON_FILE = \"data.json\"\n",
    "\n",
    "# def get_episodes(raw_dir: Path) -> List[Path]:\n",
    "#     return [path for path in raw_dir.iterdir() if path.is_dir()]\n",
    "\n",
    "# episode_paths = get_episodes(RAW_DIR)\n",
    "# print(f\"Found {len(episode_paths)} episodes.\")\n",
    "\n",
    "# episode_paths = sorted(\n",
    "#     episode_paths,\n",
    "#     key=lambda path: int(re.search(r'(\\d+)$', str(path)).group(1)) if re.search(r'(\\d+)$', str(path)) else -1\n",
    "# )\n",
    "# num_episodes = len(episode_paths)\n",
    "\n",
    "# for ep_path in tqdm.tqdm(episode_paths, desc=f\"Processing {num_episodes} episodes\"):\n",
    "#     json_path = ep_path / JSON_FILE\n",
    "#     if not json_path.exists():\n",
    "#         print(f\"Warning: {json_path} does not exist.\")\n",
    "#         continue\n",
    "\n",
    "#     try:\n",
    "#         with json_path.open('r+', encoding='utf-8') as jsonf:\n",
    "#             # 加载 JSON 文件\n",
    "#             episode_data = json.load(jsonf)\n",
    "\n",
    "#             # 修改数据\n",
    "#             for sample_data in episode_data.get(\"data\", []):\n",
    "#                 arm_states = np.array(sample_data[\"states\"].get(\"arm\", {})[\"qpos\"], dtype=np.float32)\n",
    "#                 arm_actions = np.array(sample_data[\"actions\"].get(\"arm\", {})[\"qpos\"], dtype=np.float32)\n",
    "\n",
    "#                 arm_actions = arm_states + np.clip(arm_actions - arm_states, a_min=-0.1, a_max=0.1)\n",
    "\n",
    "#                 sample_data[\"actions\"][\"arm\"][\"qpos\"] = arm_actions.tolist()\n",
    "            \n",
    "#             # 写入修改后的数据\n",
    "#             jsonf.seek(0)  # 将文件指针移动到文件开头\n",
    "#             jsonf.truncate()  # 清空文件内容\n",
    "#             json.dump(episode_data, jsonf, indent=4, ensure_ascii=False)  # 写入修改后的数据\n",
    "\n",
    "#     except json.JSONDecodeError as e:\n",
    "#         print(f\"Error decoding JSON in {json_path}: {e}\")\n",
    "#         continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robotics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
